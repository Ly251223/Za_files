{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "スクレイピング&判別.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "C-VeIBaiwUxf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6FcAjnt4R7W"
      },
      "source": [
        "# 画像スクレイピング＆AIを学習させるプログラム\n",
        "\n",
        "大きくこの4つに分類されます\n",
        "\n",
        "1. 関数の読み込み\n",
        "2. データセットの作成\n",
        "3. AIモデルの構築と学習\n",
        "4. 性能評価\n",
        "\n",
        "<!-- Project Name    : 画像スクレイピングおよび画像認識プログラム\n",
        "群馬大学ICTデータサイエンスコンソーシアム・中村の著作物です -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-VeIBaiwUxf"
      },
      "source": [
        "## ①関数の読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQUEt0qEv9eh"
      },
      "source": [
        "\n",
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Colaboratoryにプリインストールされていないパッケージをインストールする\n",
        "!pip install icrawler\n",
        "!pip install japanize_matplotlib\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "import japanize_matplotlib\n",
        "clear_output()\n",
        "print(\"ライブラリのインポートが完了しました\")\n",
        "\n",
        "# 関数の読み込み(1/2)\n",
        "def class_making(subset, img_size, ndim=3):\n",
        "  \"\"\"\n",
        "  subsetからデータとラベルを取り出す関数  \n",
        "\n",
        "  Parameters  \n",
        "  --------------  \n",
        "  subset : subset\n",
        "    データとラベルのデータセット  \n",
        "  img_size : int\n",
        "    画像のデータサイズ，正方形を想定している  \n",
        "  ndim : int\n",
        "    画像の次元数，デフォルトは3  \n",
        "  \n",
        "  Returns\n",
        "  ----------\n",
        "  data : data[1:]\n",
        "    subset内のデータ，初めの要素は空なので1から返している  \n",
        "  label : torch.tensor(labels)\n",
        "    subset内のラベル，データに合わせてそのまま使えるようにtorch.tensorでラップしている\n",
        "  \"\"\"\n",
        "\n",
        "  labels = []\n",
        "  data = subset.dataset.__getitem__(0)[0].view(1, ndim, img_size, img_size)\n",
        "  for index in subset.indices:\n",
        "    data = torch.cat((data, subset.dataset.__getitem__(index)[0].view(1,ndim,img_size,img_size)))\n",
        "    labels.append(subset.dataset.__getitem__(index)[1])\n",
        "    \n",
        "  return data[1:], torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfkTyxQc1g4H"
      },
      "source": [
        "# 関数の読み込み(2/2)\n",
        "class Tensor2Dataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  データとラベルを受け取ってDatasetオブジェクトを定義する  \n",
        "\n",
        "  Parameters\n",
        "  --------------\n",
        "  inputs : torch.tensor\n",
        "    データ  \n",
        "  labels : torch.tensor\n",
        "    ラベル\n",
        "\n",
        "  Attritubes  \n",
        "  -------------\n",
        "  data : torch.tensor\n",
        "    データ\n",
        "  labels : torch.tensor\n",
        "    ラベル\n",
        "  data_num : int\n",
        "    データの長さ\n",
        "  \"\"\"\n",
        "  def __init__(self, inputs, labels):\n",
        "    self.data = inputs\n",
        "    self.label = labels\n",
        "    self.data_num = len(self.data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data_num\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.label[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "dFiJNlbpXen6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセットの作成\n"
      ],
      "metadata": {
        "id": "Oq1WwxMjMIoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ②スクレイピングの設定と実行\n",
        "#@markdown 半角の , 区切りでスクレイピングするワードを入力して下さい\n",
        "# 0. 複数スクレイピングの準備\n",
        "スクレイピングキーワード = \"\\u767D\\u77F3\\u9EBB\\u8863, \\u5CA9\\u7530\\u525B\\u5178\"#@param {type:\"string\"}\n",
        "keywords = スクレイピングキーワード.split(',')\n",
        "最大取得枚数 =  20#@param {type:\"number\"}\n",
        "max_num = 最大取得枚数\n",
        "print(f\"スクレイピングするキーワードの確認 : {keywords}\")\n",
        "\n",
        "for keyword in keywords:\n",
        "\n",
        "  # 1. インスタンスの宣言\n",
        "  crawler = BingImageCrawler(storage={\"root_dir\": \"dataset/\" + keyword})\n",
        "  \n",
        "  # 2. crawでスクレイピング\n",
        "  crawler.crawl(keyword=keyword, max_num=max_num)\n",
        "\n",
        "clear_output()\n",
        "print(\"スクレイピングが完了しました\")\n",
        "\n",
        "zipダウンロード = False #@param {type:\"boolean\"}\n",
        "# zipファイルにまとめる\n",
        "!zip -r dataset.zip dataset\n",
        "clear_output()\n",
        "\n",
        "if zipダウンロード:\n",
        "  # zipファイルのダウンロード\n",
        "  from google.colab import files\n",
        "  files.download('dataset.zip')"
      ],
      "metadata": {
        "id": "ULy2ejx7L1ps",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLd_e8JDyVin",
        "cellView": "form"
      },
      "source": [
        "#@title ③データセットの詳細設定\n",
        "学習データとテストデータの比率 = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "学習データと検証データの比率 = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# リサイズ後の画像の大きさ\n",
        "img_size = 64\n",
        "# データセットに含める画像のパス\n",
        "img_pass = \"dataset\"\n",
        "# 学習とテストの比率\n",
        "test_ratio = 学習データとテストデータの比率\n",
        "val_ratio = 学習データと検証データの比率\n",
        "\n",
        "# 1. 整形方法の設定  \n",
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((img_size, img_size)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                ])\n",
        "\n",
        "# 2. データセットの読み込み\n",
        "data = torchvision.datasets.ImageFolder(root=img_pass, transform=transform)\n",
        "\n",
        "# データの長さ\n",
        "# 全データの長さ\n",
        "data_len = len(data)\n",
        "print(f\"データ全体 : {data_len}枚\")\n",
        "\n",
        "# 学習データの長さ\n",
        "train_len = int(data_len*test_ratio)\n",
        "print(f\"学習データ : {train_len}枚\")\n",
        "# テストデータの長さ\n",
        "test_len = data_len - train_len\n",
        "print(f\"テストデータ : {test_len}枚\")\n",
        "\n",
        "# 学習データとテストデータへの分割\n",
        "train_subset, test_subset = torch.utils.data.random_split(data, [train_len, test_len])\n",
        "\n",
        "# 学習データをDatasetクラスオブジェクトに戻す\n",
        "inputs, labels = class_making(train_subset, img_size)\n",
        "train_set = Tensor2Dataset(inputs, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcENx-QC2O0G"
      },
      "source": [
        "# AIモデルの構築と学習\n",
        "\n",
        "---\n",
        "\n",
        "<font color=\"blue\">学習の設定</font>では，どのように学習させるかを設定します\n",
        "- エポック：データセットを使い回す回数を指定します\n",
        "- バッチサイズ：一度に学習させる枚数を指定します\n",
        "- エポックごとの誤差の表示：エポックごとに、学習誤差・検証誤差・テスト誤差を表示させるか指定します\n",
        "- モデルの保存：モデルを保存するかどうかを指定します\n",
        "- 保存するモデルの名前：保存するモデルの名称を指定します\n",
        "\n",
        "<font color=\"blue\">学習</font>では，AIモデルの構築で作成したAIモデルを学習させます。スタンダードなCNNを用います"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ④学習の設定"
      ],
      "metadata": {
        "id": "KEtkx8iuO518"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ynouSLFcHj",
        "cellView": "form"
      },
      "source": [
        "エポック = 100#@param {type:\"number\"}\n",
        "バッチサイズ = 10#@param {type:\"number\"}\n",
        "エポックごとの誤差の表示 = False #@param {type:\"boolean\"}\n",
        "モデルの保存 = True #@param {type:\"boolean\"}\n",
        "保存するモデルの名前 = \"model\" #@param {type:\"string\"}\n",
        "\n",
        "def train_model(model, criterion, optimizer, epochs=エポック, batch_size=バッチサイズ, train_set=train_set, test_subset=test_subset, val_ratio=val_ratio):\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_loss_arr = []\n",
        "  validation_loss_arr = []\n",
        "  test_loss_arr = []\n",
        "\n",
        "  # テストデータは一気にテスト\n",
        "  test_inputs, test_labels = class_making(test_subset, img_size)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    validation_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    # エポックごとに交差検証\n",
        "    train_size = int(len(train_set) * val_ratio)\n",
        "    validation_size = len(train_set) - train_size\n",
        "    train_data, validation_data = torch.utils.data.random_split(train_set, [train_size, validation_size])\n",
        "\n",
        "    # 学習データはバッチで学習\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    # 検証データは一気にテスト\n",
        "    validation_inputs, validation_labels = class_making(validation_data, img_size)\n",
        "\n",
        "    # 学習モード\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "      # データ入力\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # 誤差逆伝播とパラメータの更新\n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    # 検証モード\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      # 検証データ\n",
        "      validation_loss = criterion(model(validation_inputs), validation_labels)\n",
        "      # テストデータ\n",
        "      test_loss = criterion(model(test_inputs), test_labels)\n",
        "\n",
        "    if エポックごとの誤差の表示:\n",
        "      print(\"epoch{}\\n 学習誤差: {:.4f} / 検証誤差:{:.4f} / テスト誤差:{:.4f}\".format(epoch+1, train_loss/len(train_loader), validation_loss, test_loss))\n",
        "    train_loss_arr.append(train_loss/len(train_loader))\n",
        "    validation_loss_arr.append(validation_loss)\n",
        "    test_loss_arr.append(test_loss)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    model.to(\"cpu\")\n",
        "  torch.save(model.state_dict(), f\"{保存するモデルの名前}.pth\")\n",
        "  loss_arr = {\"学習誤差\": train_loss_arr, \"検証誤差\": validation_loss_arr, \"テスト誤差\": test_loss_arr}\n",
        "  return model, loss_arr\n",
        "\n",
        "  # ニューラルネットワークのクラスを定義\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # 全結合層のニューロン数\n",
        "    self.fc_neuron = 108\n",
        "    # 層の定義\n",
        "    self.conv1 = nn.Conv2d( 3, 16, 3)\n",
        "    self.conv2 = nn.Conv2d(16, 16, 3)\n",
        "    self.conv3 = nn.Conv2d(16,  3, 3)\n",
        "    self.fc = nn.Linear(self.fc_neuron, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = self.conv1(x)\n",
        "    h = torch.max_pool2d(h, 2)\n",
        "    h = F.relu(h)\n",
        "\n",
        "    h = self.conv2(h)\n",
        "    h = torch.max_pool2d(h, 2)\n",
        "    h = F.relu(h)\n",
        "\n",
        "    h = self.conv3(h)\n",
        "    h = torch.max_pool2d(h, 2)\n",
        "    h = F.relu(h)\n",
        "\n",
        "    # 全結合層に接続するために並べ替え\n",
        "    h = h.view(-1, self.fc_neuron)\n",
        "\n",
        "    y = self.fc(h)\n",
        "    return y\n",
        "\n",
        "# 　インスタンスの宣言\n",
        "# インスタンスの名称はcnnにしましょう\n",
        "cnn = CNN()\n",
        "\n",
        "# 念の為GPUの設定をできるようにする\n",
        "# デバイスインスタンスの宣言\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# ニューラルネットワーククラスインスタンスをGPUにセット\n",
        "cnn.to(device)\n",
        "\n",
        "print(\"ニューラルネットワークの定義が完了しました\")\n",
        "\n",
        "\n",
        "# 学習\n",
        "学習方法の選択 = \"自作のモデルで学習\"\n",
        "# 誤差関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 最適化器の定義\n",
        "optimizer = optim.Adam(cnn.parameters())\n",
        "\n",
        "model = cnn if 学習方法の選択==\"自作のモデルで学習\" else transfer_model\n",
        "model, loss = train_model(model, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8ZpFEfjOfKl"
      },
      "source": [
        "# 性能評価\n",
        "\n",
        "---\n",
        "\n",
        "<font color=\"blue\">学習の評価</font>では，学習中の誤差の経過を表示して，学習後のモデルを使って予測を試してみます．\n",
        "\n",
        "- 学習経過の可視化  \n",
        "  縦軸の誤差、横軸にエポック数を取り、学習誤差・検証誤差・テスト誤差の3つを折線グラフで描画します\n",
        "  - 学習誤差：このエポックで学習に使ったデータの誤差\n",
        "  - テスト誤差：学習には絶対に使わないデータの誤差\n",
        "  - 検証誤差：このエポックでは学習に使わなかったデータの誤差\n",
        "\n",
        "\n",
        "<font color=\"blue\">認識精度の性能評価</font>では，学習データかテストデータを指定して認識精度を確認できます\n",
        "- 使うデータ：学習データかテストデータを指定します\n",
        "\n",
        "認識精度として次の3つが表示されます\n",
        "- 正解率：Accuracy：全体のうち、AIの判断が当たっていた割合\n",
        "- 的中精度：Precision：AIが乃木坂46と判断したもののうち、本当に乃木坂46だったものの割合\n",
        "- 取りこぼし率：Recall：乃木坂46全体のうち、AIが乃木坂46と認識したもの"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjEobbRTszi8"
      },
      "source": [
        "### ⑤学習経過の可視化と判定率の算出\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD1oOJp_3O8d",
        "cellView": "form"
      },
      "source": [
        "# 折れ線グラフの作成\n",
        "for key, value in loss.items():\n",
        "  plt.plot(range(1, len(value) + 1), value, label=key)\n",
        "\n",
        "# グラフタイトルの設定\n",
        "plt.title(\"学習経過\")\n",
        "\n",
        "# 凡例とラベルの追加\n",
        "plt.legend()\n",
        "plt.xlabel(\"エポック数\")\n",
        "plt.ylabel(\"誤差\")\n",
        "\n",
        "# グラフの表示\n",
        "plt.show()\n",
        "\n",
        "使うデータ = \"\\u5B66\\u7FD2\\u30C7\\u30FC\\u30BF\"#@param [\"学習データ\", \"テストデータ\"]{type:\"string\"}\n",
        "data_type = 使うデータ\n",
        "一度に表示する枚数 = 8#@param {type:\"number\"}\n",
        "batch_size = 一度に表示する枚数\n",
        "\n",
        "モデルの選択 = \"自作のモデル\" #@param [\"自作のモデル\", \"転移学習モデル\"] {allow-input: false}\n",
        "\n",
        "\n",
        "# 入力画像を表示する関数の作成\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    plt.title(\"予測に使った画像\")\n",
        "    plt.imshow(img.transpose(0, 1).transpose(1, 2))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def prediction(model, inputs):\n",
        "\n",
        "  imshow(torchvision.utils.make_grid(inputs))\n",
        "  \n",
        "  outputs = model(inputs.to(device))\n",
        "  outputs = outputs.to(\"cpu\").argmax(dim=1)\n",
        "\n",
        "  # 数値から名称に変換\n",
        "  ans = []\n",
        "  sorted_keys = sorted(keywords)\n",
        "  for label in outputs:\n",
        "    for index in range(len(keywords)):\n",
        "      if label==index:\n",
        "        ans.append(sorted_keys[index])\n",
        "  print(\"AIの予測結果\", ans)\n",
        "\n",
        "if data_type==\"学習データ\":\n",
        "  prediction_subset = train_subset\n",
        "else :\n",
        "  prediction_subset = test_subset\n",
        "\n",
        "model = cnn if モデルの選択==\"自作のモデル\" else transfer_model\n",
        "\n",
        "prediction_loader = torch.utils.data.DataLoader(prediction_subset, batch_size=batch_size, shuffle=True)\n",
        "inputs, _ = iter(prediction_loader).next()\n",
        "prediction(model, inputs)\n",
        "\n",
        "使うデータ = \"\\u5B66\\u7FD2\\u30C7\\u30FC\\u30BF\"#@param [\"学習データ\", \"テストデータ\"]{type:\"string\"}\n",
        "data_type = 使うデータ\n",
        "\n",
        "if data_type==\"学習データ\":\n",
        "  verification_subset = train_subset\n",
        "else :\n",
        "  verification_subset = test_subset\n",
        "\n",
        "def performance_chesk(verification_subset):\n",
        "  verification_inputs, verification_labels = class_making(verification_subset, img_size)\n",
        "\n",
        "  outputs = cnn(verification_inputs.to(device))\n",
        "  outputs = outputs.to(\"cpu\").argmax(dim=1)\n",
        "\n",
        "  accuracy = accuracy_score(verification_labels, outputs)\n",
        "  precision = precision_score(verification_labels, outputs, average=None)\n",
        "  recall = recall_score(verification_labels, outputs, average=None)\n",
        "  print(\"正解率 (%)：\", accuracy*100,\"%\")\n",
        "  print(\"的中精度(%) :\", precision*100,\"%\")\n",
        "  print(\"取りこぼし率(%) :\", recall*100,\"%\")\n",
        "\n",
        "performance_chesk(verification_subset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⑥画像のアップロードと判別"
      ],
      "metadata": {
        "id": "w8BZJWrPOqZB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPGPPQxAK2Xg"
      },
      "source": [
        "image_file = take_photo()\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "image = img.imread(image_file)\n",
        "plt.title(\"アップロードした画像\")\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "model = cnn if モデルの選択==\"自作のモデル\" else transfer_model\n",
        "model_name = \"model.pth\"\n",
        "clear_output()\n",
        "model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "image = Image.open(image_file)\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((img_size, img_size)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                ])\n",
        "image = transform(image).unsqueeze(0).float()\n",
        "prediction(model, image)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}